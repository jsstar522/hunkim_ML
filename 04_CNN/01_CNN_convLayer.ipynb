{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_CNN_convLayer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsstar522/hunkim_ML/blob/master/04_CNN/01_CNN_convLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF0n071duR50",
        "colab_type": "text"
      },
      "source": [
        "# Convolution Neural Network\n",
        "\n",
        "## Convolution Neural Network와 이미지 인식\n",
        "`CNN`은 입력을 **여러개로 나눠서** 받는 Network입니다. 예를들어 사람이 고양이 사진을 보았을 때, 이미지가 시신경을 통해 뇌로 전달 됩니다. 이 때, 고양이 사진 전체가 뇌의 뉴런들을 동시다발적으로 활성화 시키는 것이 아닙니다. 사진을 볼 때 사진의 **특징들(\"귀가 뾰족하다\", \"꼬리가 있다\", \"눈이 날카롭다\")이 나눠서 전달**되고 이에 해당하는 뉴런들이 활성화 되는 것입니다. **즉, 하나의 input이 여러개의 input으로 나뉘어서 전달된 후 해당 특징들이 해당 뉴런들을 활성화 시키는 것입니다.** 이 아이디어로 `Convolution(종합) Neural Network`의 모델이 만들어졌습니다. \n",
        "\n",
        "## 이미지 filtering\n",
        "이미지의 일부를 뽑아내는 과정(filtering)을 살펴보겠습니다.\n",
        "\n",
        "![CNN image](figure/1.png)\n",
        "\n",
        "왼쪽에 있는 이미지는 5x5의 원본 input data입니다. 이를 부분부분 입력값을 나누기 위해서 2x2 filter를 사용합니다. 가장 왼쪽, 가장 위쪽 구석에 2x2 filter를 가져다 두고 **하나의 값**으로 만듭니다. 하나의 값을 만들기 위해서 우리가 자주 사용하던 hypothesis인 $WX + b$의 수식을 이용합니다. 맨 첫번째 filtering(**남색 area**)을 계산해보겠습니다.\n",
        "\n",
        "$$\n",
        "\\begin{pmatrix} 2.0&3.0&2.0&1.5 \\end{pmatrix} \\cdot \\begin{pmatrix} w_1 \\\\ w_2 \\\\ w_3 \\\\ w_4 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "이제 저 4개의 값을 한줄로 나열해서 1x4 행렬로 두고, weight이 곱해져 하나의 값으로 나와야 하므로 weight은 4x1의 형태를 가지고 있어야 합니다. 그리고 이어서 바로 오른쪽에 있는 **연두색 area**도 같은 방식으로 계산합니다. 이런식으로 가장 오른쪽, 가장 아래쪽 구석까지 내려가면 총 4x4개의 값이 나오게 됩니다. (오른쪽 아래 방향으로 각각 4번식 이동 가능하므로 filtering 이후 input 개수는 16개가 된다.)\n",
        "\n",
        "위와 같은 방식은 **한칸씩** 이동했으므로 4x4개의 input으로 filtering 됐지만 두칸씩 이동하는 것도 가능합니다. 이렇게 이동시킬 때의 단위를 stride라고 합니다. 원본 input 크기와 filter 크기, stride를 알면 filtering 된 새로운 input 크기를 알 수 있습니다. 학습을 위해서 이 크기를 꼭 계산해놔야만 하죠. NxN의 원본 input과 MxM의 filter 크기, 이동시키는 칸의 개수일 때, **filtering 된 값의 크기 KxK**는 다음과 같이 나옵니다.\n",
        "\n",
        "$$\n",
        "K = (N-M)/stride + 1\n",
        "$$\n",
        "\n",
        "예를들어 7x7의 원본 데이터에 3x3의 filter와 3 stride로 filtering 시키면 2.33x2.33의 값이 나오기 때문에 사용할 수 없습니다.\n",
        "\n",
        "## Padding\n",
        "위의 filtering을 거치게 되면 이미지가 계속 작아집니다. 이미지의 일부를 하나로 함축했으므로 정보를 잃어버린다는 뜻이죠. **최대한 정보를 잃어버리지 않기 위해 padding을 사용합니다. padding은 원본 input 가장자리에 0을 두르는 것입니다.**\n",
        "\n",
        "![padding](figure/2.png)\n",
        "\n",
        "5x5의 원본이미지에 padding을 해주고 2x2으로 filtering된 input의 크기를 구해보면 stride가 1일 때, 똑같이 5x5가 나오는 것을 알 수 있습니다.\n",
        "\n",
        "## 여러개의 filter\n",
        "filter를 하나만 놓지 않고 여러개를 놓을 수 있습니다. 그렇다면 filter의 개수만큼 다양한 정보가 쌓입니다.\n",
        "\n",
        "![sequence](figure/3.png)\n",
        "\n",
        "첫번째 layer는 28x28의 원본 input data를 5x5 filter로 1 strade만큼 $n_1$개 filtering 한 것입니다. 그렇다면 첫번째 layer에서는 $(28-5)/1 + 1 = 24$의 계산으로 24x24의 data가 $n_1$개 만큼 생성됩니다. 각각의 filtering된 data는 다른 weight 값을 가지고 있으므로 다양한 정보를 담고 있습니다. 그리고 이 과정을 여러번 반복하면 multi layer가 형성됩니다."
      ]
    }
  ]
}